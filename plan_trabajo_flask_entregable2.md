# üß≠ Plan de Trabajo ‚Äî Proyecto Flask: Entregable 2 - Integraci√≥n con IA (OpenAI SDK)

Este documento detalla el plan de desarrollo para extender la aplicaci√≥n Flask del Entregable 1 con capacidades de Inteligencia Artificial utilizando el SDK de OpenAI. Se mantiene la arquitectura desacoplada y escalable del entregable anterior, a√±adiendo nuevos campos al modelo Task y 4 nuevos endpoints especializados en IA.

---

## üìã RESUMEN DE CAMBIOS REQUERIDOS

### ‚ú® Nuevos campos en el modelo Task:
- `category` ‚Üí Nuevo campo (str o enum): Frontend, Backend, Testing, Infra, etc.
- `risk_analysis` ‚Üí Nuevo campo texto para an√°lisis de riesgos
- `risk_mitigation` ‚Üí Nuevo campo texto para plan de mitigaci√≥n de riesgos

### ü§ñ Nuevos endpoints con IA:
- `POST /ai/tasks/describe` ‚Üí Generar descripci√≥n con LLM
- `POST /ai/tasks/categorize` ‚Üí Clasificar tarea por categor√≠a con LLM
- `POST /ai/tasks/estimate` ‚Üí Estimar esfuerzo en horas con LLM
- `POST /ai/tasks/audit` ‚Üí An√°lisis de riesgos y mitigaci√≥n con LLM

### üìä Monitoreo de tokens:
- Registrar el n√∫mero de tokens consumidos en cada interacci√≥n con OpenAI

---

## üß© FASE 0: Preparaci√≥n del entorno para IA

### üéØ Objetivo
Configurar el entorno para trabajar con APIs de IA y gestionar tokens de consumo.

### ‚úÖ Tareas

- **Instalar nuevas dependencias:**
  ```bash
  pip install openai tiktoken python-dotenv
  ```
- **Actualizar `requirements.txt`** con las nuevas dependencias:
  ```
  openai>=1.0.0
  tiktoken>=0.5.0
  python-dotenv>=1.0.0
  ```
- **Configurar variables de entorno** para la API key de OpenAI:
  - Crear archivo `.env` en la ra√≠z del proyecto
  - A√±adir `OPENAI_API_KEY=tu_api_key_aqui`
  - Actualizar `.gitignore` para excluir `.env`
- **Crear servicio de configuraci√≥n** en `app/config/ai_config.py`:
  - Cargar variables de entorno
  - Configurar cliente OpenAI
  - Definir modelos y par√°metros por defecto

---

## üß± FASE 1: Extensi√≥n del modelo Task y esquemas

### üéØ Objetivo
A√±adir los nuevos campos al modelo de dominio y actualizarlo en todos los niveles de la arquitectura.

### ‚úÖ Tareas

- **Actualizar `app/models/task.py`:**
  - A√±adir campos: `category`, `risk_analysis`, `risk_mitigation`
  - Modificar `__init__`, `to_dict()` y `from_dict()`
  - Mantener retrocompatibilidad con tareas existentes

- **Actualizar `app/schemas/task_schema.py`:**
  - Crear enum `TaskCategory` para categor√≠as v√°lidas
  - A√±adir validaciones para los nuevos campos
  - Crear esquemas espec√≠ficos para cada endpoint de IA:
    - `TaskDescribeSchema` (sin description)
    - `TaskCategorizeSchema` (sin category)
    - `TaskEstimateSchema` (sin effort_hours)
    - `TaskAuditSchema` (sin risk_analysis y risk_mitigation)

- **Verificar compatibilidad:**
  - Ejecutar pruebas existentes para asegurar que no hay regresiones
  - Actualizar archivo `tasks.json` de prueba si es necesario

---

## ü§ñ FASE 2: Servicio de IA para interacci√≥n con OpenAI

### üéØ Objetivo
Crear un servicio centralizado para manejar todas las interacciones con OpenAI, incluyendo el monitoreo de tokens (sin persistencia separada).

### ‚úÖ Tareas

- **Crear `app/services/ai_service.py`:**
  - Clase `OpenAIService` con m√©todos para cada tipo de petici√≥n
  - Sistema de prompts (system + user) parametrizables
  - Manejo de errores de API (rate limits, errores de red, etc.)
  - Contador de tokens usando tiktoken

- **M√©todos espec√≠ficos en `OpenAIService`:**
  - `generate_description(task_data)` ‚Üí Para endpoint describe
  - `categorize_task(task_data)` ‚Üí Para endpoint categorize
  - `estimate_effort(task_data)` ‚Üí Para endpoint estimate
  - `analyze_risks(task_data)` ‚Üí Para endpoint audit (an√°lisis)
  - `generate_mitigation(task_data, risk_analysis)` ‚Üí Para endpoint audit (mitigaci√≥n)

---

## üßÆ FASE 2B: Acumulaci√≥n de tokens en la tarea

### üéØ Objetivo
Registrar y acumular el n√∫mero de tokens consumidos por cada tarea directamente en el modelo y esquema de la Task.

### ‚úÖ Tareas

- **Modificar `app/models/task.py`:**
  - A√±adir campo `token_usage` (int, por defecto 0) para almacenar el total acumulado de tokens consumidos por la tarea.
  - Actualizar m√©todos `__init__`, `to_dict()` y `from_dict()` para soportar el nuevo campo.
- **Modificar `app/schemas/task_schema.py`:**
  - A√±adir campo `token_usage` en los esquemas de tarea.
  - Validar que sea un entero >= 0.
- **Integrar la l√≥gica de acumulaci√≥n de tokens en las fases 3 y 4 (ver detalles en cada fase).**
- (Opcional) Mostrar el coste estimado acumulado junto con el campo de tokens.

---

## üõ†Ô∏è FASE 3: Manager de IA para l√≥gica de negocio (mejorada)

### üéØ Objetivo
Crear un manager que orqueste las operaciones de IA manteniendo la separaci√≥n de responsabilidades y actualice el campo de tokens acumulados.

### ‚úÖ Tareas

- **Crear `app/services/ai_task_manager.py`:**
  - Clase `AITaskManager` que utiliza `OpenAIService` y `TaskManager`
  - M√©todos que implementan la l√≥gica de cada endpoint de IA
  - Validaci√≥n de datos antes de enviar a OpenAI
  - Post-procesamiento de respuestas (parsing, limpieza, validaci√≥n)
  - **En cada m√©todo, sumar los tokens consumidos (devueltos por OpenAIService) al campo `token_usage` de la tarea y persistir el valor actualizado.**

- **M√©todos principales:**
  - `describe_task(task)` ‚Üí Genera description y actualiza la tarea
  - `categorize_task(task)` ‚Üí Clasifica y asigna category
  - `estimate_task_effort(task)` ‚Üí Estima effort_hours (parsing a n√∫mero)
  - `audit_task_risks(task)` ‚Üí Genera risk_analysis y risk_mitigation

- **Integraci√≥n con TaskManager:**
  - Reutilizar TaskManager existente para persistencia
  - Mantener separaci√≥n entre l√≥gica de IA y l√≥gica de dominio

---

## üåê FASE 4: Nuevas rutas para endpoints de IA (mejorada)

### üéØ Objetivo
Implementar los 4 nuevos endpoints RESTful que integren las capacidades de IA y aseguren la actualizaci√≥n del campo `token_usage` en cada operaci√≥n.

### ‚úÖ Tareas

- **Crear `app/routes/ai_routes.py`:**
  - Nuevo Blueprint para rutas de IA: `ai_tasks`
  - Separar responsabilidades: rutas de CRUD vs rutas de IA

- **Implementar endpoints espec√≠ficos:**

  1. **`POST /ai/tasks/describe`:**
     - Recibe: Task con description vac√≠a
     - Valida: Todos los campos excepto description
     - Llama al manager de IA, actualiza y persiste el campo `token_usage` de la tarea
     - Retorna: Task con description generada y tokens acumulados

  2. **`POST /ai/tasks/categorize`:**
     - Recibe: Task sin category
     - Valida: Todos los campos excepto category  
     - Llama al manager de IA, actualiza y persiste el campo `token_usage` de la tarea
     - Retorna: Task con category asignada y tokens acumulados

  3. **`POST /ai/tasks/estimate`:**
     - Recibe: Task sin effort_hours
     - Valida: title, description, category obligatorios
     - Llama al manager de IA, actualiza y persiste el campo `token_usage` de la tarea
     - Retorna: Task con effort_hours estimado (n√∫mero) y tokens acumulados

  4. **`POST /ai/tasks/audit`:**
     - Recibe: Task completa excepto risk_analysis y risk_mitigation
     - Genera: An√°lisis de riesgos y plan de mitigaci√≥n
     - Llama al manager de IA, actualiza y persiste el campo `token_usage` de la tarea
     - Retorna: Task con ambos campos completados y tokens acumulados

- **Manejo de errores espec√≠ficos de IA:**
  - Rate limits de OpenAI
  - Errores de parsing (ej: effort_hours no num√©rico)
  - Timeouts de API
  - Respuestas vac√≠as o inv√°lidas

- **Registrar el nuevo Blueprint** en `app/__init__.py`

---

## üìä FASE 5: Monitoreo y logging de tokens

### üéØ Objetivo
Implementar un sistema de monitoreo del consumo de tokens y costos de OpenAI.

### ‚úÖ Tareas

- **Crear `app/services/token_monitor.py`:**
  - Decorador para medir autom√°ticamente el consumo de tokens
  - C√°lculo de costos estimados por modelo
  - Logs detallados de cada operaci√≥n

- **Crear endpoints de monitoreo:**
  - `GET /ai/stats/tokens` ‚Üí Estad√≠sticas de consumo total
  - `GET /ai/stats/operations` ‚Üí Consumo por tipo de operaci√≥n
  - `GET /ai/stats/costs` ‚Üí Estimaci√≥n de costos

- **Dashboard b√°sico en endpoint:**
  - Resumen de tokens consumidos hoy/semana/mes
  - Operaci√≥n m√°s costosa
  - Promedio de tokens por operaci√≥n

---

## üß™ FASE 6: Pruebas automatizadas para IA

### üéØ Objetivo
Extender las pruebas existentes para cubrir las nuevas funcionalidades de IA.

### ‚úÖ Tareas

- **Crear `tests/test_ai_endpoints.py`:**
  - Pruebas para cada endpoint de IA
  - Mocks de OpenAI para evitar consumo real de tokens
  - Pruebas de manejo de errores espec√≠ficos de IA

- **Crear `tests/test_ai_services.py`:**
  - Pruebas unitarias para `OpenAIService`
  - Pruebas de parsing y validaci√≥n de respuestas
  - Pruebas de contador de tokens

- **Actualizar `tests/test_tasks.py`:**
  - Verificar compatibilidad con nuevos campos
  - Pruebas de migraci√≥n de datos existentes

- **Crear fixtures para IA:**
  - Respuestas mockeadas de OpenAI
  - Tareas de ejemplo para cada tipo de operaci√≥n
  - Configuraci√≥n de testing sin consumir API real

---

## üìö FASE 7: Actualizaci√≥n de documentaci√≥n

### üéØ Objetivo
Documentar las nuevas funcionalidades y actualizar la gu√≠a de uso.

### ‚úÖ Tareas

- **Actualizar `README.md`:**
  - Secci√≥n de configuraci√≥n de OpenAI API
  - Documentaci√≥n de nuevos endpoints
  - Ejemplos de uso de cada endpoint de IA
  - Informaci√≥n sobre monitoreo de tokens

- **Actualizar `proyecto_tareas.ipynb`:**
  - Ejemplos pr√°cticos de cada endpoint de IA
  - C√≥mo interpretar las respuestas de IA
  - Monitoreo de consumo de tokens
  - Casos de uso reales

- **Docstrings actualizados:**
  - Documentar todos los nuevos m√©todos y clases
  - Incluir informaci√≥n sobre tokens y costos
  - Ejemplos de uso en docstrings principales

---

## ‚ö° FASE 8: Optimizaci√≥n y mejores pr√°cticas

### üéØ Objetivo
Optimizar el rendimiento y implementar mejores pr√°cticas para producci√≥n.

### ‚úÖ Tareas

- **Optimizaci√≥n de prompts:**
  - Refinar prompts para mayor precisi√≥n
  - Minimizar tokens sin perder calidad
  - Implementar prompt templates reutilizables

- **Cach√© de respuestas:**
  - Cach√© simple para evitar repetir consultas id√©nticas
  - TTL configurable para respuestas de IA

- **Rate limiting:**
  - Implementar l√≠mites por usuario/IP
  - Manejo graceful de rate limits de OpenAI

- **Configuraci√≥n por entornos:**
  - Configuraci√≥n espec√≠fica para dev/test/prod
  - Modelos diferentes seg√∫n entorno
  - L√≠mites de tokens por entorno

---

## üì¶ FASE FINAL: Empaquetado y entrega

### ‚úÖ Tareas

- **Verificaci√≥n final:**
  - Todas las pruebas pasan (incluyendo las nuevas)
  - Todos los endpoints funcionan correctamente
  - Documentaci√≥n actualizada y completa
  - Variables de entorno documentadas

- **Limpieza de c√≥digo:**
  - Eliminar c√≥digo comentado
  - Revisar imports no utilizados
  - Verificar estilo de c√≥digo consistente

- **Empaquetado:**
  - Crear `m3_entregable2_nombre_apellido.zip`
  - Incluir `.env.example` con estructura de variables
  - Excluir `.env` real (con API keys)
  - Incluir archivo de migraci√≥n de datos si es necesario

---

## ‚úÖ CHECKLIST DE VERIFICACI√ìN FINAL

### üéØ Verificaci√≥n exhaustiva antes de la entrega

- [ ] **Configuraci√≥n:**
  - [ ] OpenAI API key configurada correctamente
  - [ ] Todas las dependencias instaladas (`pip install -r requirements.txt`)
  - [ ] Variables de entorno documentadas en `.env.example`

- [ ] **Modelo extendido:**
  - [ ] Clase `Task` incluye nuevos campos: `category`, `risk_analysis`, `risk_mitigation`
  - [ ] Esquemas de validaci√≥n actualizados
  - [ ] Retrocompatibilidad con datos existentes mantenida

- [ ] **Endpoints de IA implementados:**
  - [ ] `POST /ai/tasks/describe` funciona correctamente
  - [ ] `POST /ai/tasks/categorize` clasifica apropiadamente
  - [ ] `POST /ai/tasks/estimate` retorna n√∫mero v√°lido de horas
  - [ ] `POST /ai/tasks/audit` genera an√°lisis y mitigaci√≥n

- [ ] **Servicios de IA:**
  - [ ] `OpenAIService` maneja todas las interacciones con OpenAI
  - [ ] Contador de tokens funciona correctamente
  - [ ] Manejo de errores robusto (rate limits, timeouts, etc.)

- [ ] **Monitoreo:**
  - [ ] Tokens consumidos se registran correctamente
  - [ ] Endpoints de estad√≠sticas funcionan
  - [ ] Logs detallados de operaciones de IA

- [ ] **Pruebas:**
  - [ ] Todas las pruebas existentes siguen pasando
  - [ ] Nuevas pruebas para endpoints de IA implementadas
  - [ ] Pruebas usan mocks (no consumen API real)

- [ ] **Documentaci√≥n:**
  - [ ] `README.md` actualizado con nueva funcionalidad
  - [ ] `proyecto_tareas.ipynb` incluye ejemplos de IA
  - [ ] Docstrings a√±adidos a todas las nuevas clases y m√©todos

- [ ] **Funcionalidad manual verificada:**
  - [ ] Servidor Flask arranca sin errores
  - [ ] Endpoints CRUD originales siguen funcionando
  - [ ] Cada endpoint de IA retorna respuestas v√°lidas
  - [ ] Monitoreo de tokens muestra datos correctos

---

## üéØ ENTREGABLE

**Archivo:** `m3_entregable2_nombre_apellido.zip`

**Contenido m√≠nimo:**
- C√≥digo fuente completo con extensiones de IA
- `requirements.txt` actualizado
- `.env.example` con estructura de variables
- `README.md` con documentaci√≥n completa
- `proyecto_tareas.ipynb` con ejemplos
- Archivos de prueba actualizados
- Datos de ejemplo en `tasks.json`

**Exclusiones:**
- Carpeta `venv/`
- Archivo `.env` (con API keys reales)
- Carpetas `__pycache__/`
- Archivos temporales del sistema

---

‚úÖ **¬°Proyecto listo para entregar cuando todos los puntos est√©n verificados!**
